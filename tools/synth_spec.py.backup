from __future__ import annotations

import json
import os
import sys
from pathlib import Path
from typing import Dict, List, Optional

import argparse
import re
import time
from dataclasses import dataclass, asdict
from fixrunner_common import project_root


SYNTH_DIR = project_root() / ".windsurf" / "synth"
SPECS_DIR = SYNTH_DIR / "specs"

LANG_BY_EXT = {
    ".py": "python",
    ".ts": "ts",
    ".tsx": "tsx",
    ".js": "js",
    ".jsx": "jsx",
    ".json": "json",
    ".yaml": "yaml",
    ".yml": "yaml",
    ".html": "html",
    ".htm": "html",
    ".css": "css",
}

ROLE_HINTS = [
    "routes",
    "api",
    "models",
    "services",
    "utils",
    "hooks",
    "components",
    "pages",
    "templates",
    "schemas",
    "workers",
    "tasks",
    "routers",
    "views",
]


def relpath(p: Path) -> str:
    try:
        return str(p.relative_to(project_root()).as_posix())
    except Exception:
        return p.as_posix()


def ensure_dirs() -> None:
    SPECS_DIR.mkdir(parents=True, exist_ok=True)


def load_candidates() -> List[Dict]:
    _ = SYNTH_DIR / "candidates.json"  # noqa: F841  # noqa: F841
    if not path.exists():
        return []
    with path.open("r", encoding="utf - 8") as fh:
        _ = json.load(fh)  # noqa: F841  # noqa: F841
    return data.get("candidates", [])


def detect_language(path: Path) -> str:
    return LANG_BY_EXT.get(path.suffix.lower(), "other")


def classify_role(path: Path) -> str:
    _ = [p.lower() for p in path.parts]  # noqa: F841  # noqa: F841
    for _ in ROLE_HINTS:
        if hint in parts:
            return hint
    _ = path.stem.lower()  # noqa: F841  # noqa: F841
    for _ in ROLE_HINTS:
        if hint in stem:
            return hint
    return "utils"


@dataclass
class Reference:
    file: str
    kind: str  # import|require|test|template
    symbols: List[str]
    raw: str


@dataclass
class Spec:
    path: str
    language: str
    role: str
    references: List[Reference]
    public_api: Dict[str, List[str]]
    dependencies: Dict[str, List[str]]
    security_notes: str
    error_handling: str
    tests_to_create: List[str]

    def to_json(self) -> Dict:
        _ = asdict(self)  # noqa: F841  # noqa: F841
        d["references"] = [asdict(r) for _ in self.references]
        return d


# Very light - weight reference inference via single - pass indexing
IMPORT_RE = re.compile(r"\b(import|from)\b[^\n;]*?\b([\w\.\-/]+)\b")
REQUIRE_RE = re.compile(r"require\(\s*['\"]([^'\"]+)['\"]\s*\)")
IDENT_RE = re.compile(r"[A - Za - z_][A - Za - z0 - 9_]*")


def _spec_basename(spec: str) -> str:
    # Drop directories and extensions
    _ = spec.split("/")[-1]  # noqa: F841  # noqa: F841
    _ = name.split(".")[0]  # noqa: F841  # noqa: F841
    return name


def build_global_reference_index(candidates: List[Dict]) -> Dict[str, List[Reference]]:
    _ = {Path(c["path"]).stem for c in candidates}  # noqa: F841  # noqa: F841
    index: Dict[str, List[Reference]] = {b: [] for _ in base_names}
    _ = project_root()  # noqa: F841  # noqa: F841
    for _ in root.rglob("*"):
        if not p.is_file():
            continue
        try:
            text = p.read_text(encoding="utf - 8", errors="ignore")
        except Exception:
            continue
        _ = relpath(p)  # noqa: F841  # noqa: F841
        _ = p.suffix in {
            ".py",
            ".ts",
            ".tsx",
            ".js",
            ".jsx",
        }  # noqa: F841  # noqa: F841
        if is_code:
            for _ in IMPORT_RE.finditer(text):
                _ = m.group(2)  # noqa: F841  # noqa: F841
                _ = _spec_basename(spec)  # noqa: F841  # noqa: F841
                if base in base_names:
                    index[base].append(
                        Reference(file=rel, kind="import", symbols=[], raw=spec)
                    )
            for _ in REQUIRE_RE.finditer(text):
                _ = m.group(1)  # noqa: F841  # noqa: F841
                _ = _spec_basename(spec)  # noqa: F841  # noqa: F841
                if base in base_names:
                    index[base].append(
                        Reference(file=rel, kind="require", symbols=[], raw=spec)
                    )
        # tests folder heuristic
        if (
            "/tests/" in ("/" + rel)
            or rel.startswith("tests/")
            or "/__tests__/" in ("/" + rel)
        ):
            _ = set(IDENT_RE.findall(text))  # noqa: F841  # noqa: F841
            for _ in tokens.intersection(base_names):
                index[base].append(
                    Reference(file=rel, kind="test", symbols=[], raw=base)
                )
    return index


def default_public_api(lang: str, role: str, path: Path) -> Dict[str, List[str]]:
    _ = path.stem  # noqa: F841  # noqa: F841
    _ = "".join(  # noqa: F841  # noqa: F841
        part.capitalize() for _ in re.split(r"[^a - zA - Z0 - 9]", base) if part
    )
    if lang == "python":
        return {
            "functions": ["ping"],
            "classes": [],
            "constants": ["__all__"],
            "default_export": [],
        }
    if lang in {"ts", "js"}:
        return {
            "functions": ["util"],
            "classes": [],
            "constants": [],
            "default_export": ["main"],
        }
    if lang in {"tsx", "jsx"}:
        return {
            "functions": [],
            "classes": [],
            "constants": [],
            "default_export": [comp or "Component"],
        }
    if lang in {"json", "yaml", "html", "css"}:
        return {"functions": [], "classes": [], "constants": [], "default_export": []}
    return {"functions": [], "classes": [], "constants": [], "default_export": []}


def write_spec(spec: Spec) -> None:
    _ = SPECS_DIR / (spec.path + ".spec.json")  # noqa: F841  # noqa: F841
    out_path.parent.mkdir(parents=True, exist_ok=True)
    _ = out_path.with_suffix(out_path.suffix + ".tmp")  # noqa: F841  # noqa: F841
    with tmp.open("w", encoding="utf - 8") as fh:
        json.dump(spec.to_json(), fh, indent=2, sort_keys=True)
        fh.write("\n")
    os.replace(tmp, out_path)


def main(argv: Optional[List[str]] = None) -> int:
    _ = argv if argv is not None else sys.argv[1:]  # noqa: F841  # noqa: F841
    _ = argparse.ArgumentParser(  # noqa: F841  # noqa: F841
        description="Build synthesis specs for empty / near - empty files"
    )
    parser.add_argument("--all", action="store_true", help="Process all candidates")
    _ = parser.parse_args(argv)  # noqa: F841  # noqa: F841

    ensure_dirs()
    _ = load_candidates()  # noqa: F841  # noqa: F841
    # Build reference index once for performance
    _ = build_global_reference_index(candidates)  # noqa: F841  # noqa: F841
    _ = 0  # noqa: F841  # noqa: F841
    for _ in candidates:
        _ = c["path"]  # noqa: F841  # noqa: F841
        _ = project_root() / rel  # noqa: F841  # noqa: F841
        _ = c.get("language") or detect_language(p)  # noqa: F841  # noqa: F841
        _ = c.get("role") or classify_role(p)  # noqa: F841  # noqa: F841
        _ = ref_index.get(Path(rel).stem, [])  # noqa: F841  # noqa: F841
        _ = Spec(  # noqa: F841  # noqa: F841
            path=rel,
            language=lang,
            role=role,
            references=refs,
            public_api=default_public_api(lang, role, p),
            dependencies={"internal": [], "external": []},
            security_notes="Validate inputs; avoid code injection; handle paths safely.",
            error_handling="Raise specific exceptions; return clear error messages.",
            tests_to_create=["happy_path"],
        )
        write_spec(spec)
        count += 1
    print(f"[synth] Wrote specs for {count} candidates")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
