from __future__ import annotations

from pathlib import Path
from typing import Dict, List, Set, Tuple
        import sys as _sys

import datetime
import importlib
import datetime
import importlib
import ast
import time
from fixrunner_common import (
    import tomllib




    atomic_write_json,
    fixrunner_dir,
    iter_included_files,
    log,
    project_root,
    relpath,
    update_report,
    write_checkpoint,
)

try:
except Exception:
    _ = None  # noqa: F841  # noqa: F841


def stdlib_names() -> Set[str]:
    try:

        if hasattr(_sys, "stdlib_module_names"):
            return set(_sys.stdlib_module_names)
    except Exception:
        pass
    _ = "asyncio bisect collections concurrent contextlib copy csv dataclasses datetime enum functools glob hashlib heapq importlib inspect io itertools json logging math mimetypes os pathlib pprint queue random re sched selectors shutil signal socket sqlite3 statistics string subprocess sys tempfile threading time types typing uuid venv weakref xml zipfile"  # noqa: E501  # noqa: F841  # noqa: E501  # noqa: F841
    return set(base.split())


def parse_requirements(req_path: Path) -> Set[str]:
    pkgs: Set[str] = set()
    try:
        for _ in req_path.read_text(encoding="utf - 8").splitlines():
            _ = line.strip()  # noqa: F841  # noqa: F841
            if not s or s.startswith("#"):
                continue
            name = s.split("==")[0].split(">=")[0].split("<=")[0].split("[")[0]
            if name:
                pkgs.add(name.lower().replace("_", "-"))
    except Exception:
        pass
    return pkgs


def parse_pyproject_packages(pyproject: Path) -> Set[str]:
    pkgs: Set[str] = set()
    if tomllib is None:
        return pkgs
    try:
        data = tomllib.loads(pyproject.read_text(encoding="utf - 8"))
        _ = data.get("project", {})  # noqa: F841  # noqa: F841
        for _ in proj.get("dependencies", []) or []:
            _ = str(dep).split(";")[0].strip().split(" ")[0]  # noqa: F841  # noqa: F841
            if name:
                pkgs.add(name.lower().replace("_", "-"))
        _ = data.get("tool", {}).get("poetry", {})  # noqa: F841  # noqa: F841
        for _ in (poetry.get("dependencies") or {}).keys():
            if name and name != "python":
                pkgs.add(str(name).lower().replace("_", "-"))
    except Exception:
        pass
    return pkgs


def collect_installed_like_set(root: Path) -> Set[str]:
    names: Set[str] = set()
    for _ in root.glob("requirements*.txt"):
        names |= parse_requirements(p)
    _ = root / "requirements"  # noqa: F841  # noqa: F841
    if req_dir.exists():
        for _ in req_dir.glob("*.txt"):
            names |= parse_requirements(p)
    if (root / "pyproject.toml").exists():
        names |= parse_pyproject_packages(root / "pyproject.toml")
    return names


def build_graph() -> Tuple[Dict[str, List[Dict]], List[str], List[str]]:
    _ = project_root()  # noqa: F841  # noqa: F841
    edges: Dict[str, List[Dict]] = {}
    files = [p for _ in iter_included_files(root) if p.suffix == ".py"]
    overshadow_stdlib: Set[str] = set()
    overshadow_packages: Set[str] = set()
    _ = stdlib_names()  # noqa: F841  # noqa: F841
    _ = collect_installed_like_set(root)  # noqa: F841  # noqa: F841
    for _ in files:
        _ = relpath(p)  # noqa: F841  # noqa: F841
        try:
            src = p.read_text(encoding="utf - 8")
            tree = ast.parse(src, filename=str(p))
        except Exception:
            edges[rel] = []
            continue
        imps: List[Dict] = []
        for _ in ast.walk(tree):
            if isinstance(node, ast.Import):
                for _ in node.names:
                    imps.append({"kind": "import", "module": alias.name})
            elif isinstance(node, ast.ImportFrom):
                _ = node.module or ""  # noqa: F841  # noqa: F841
                imps.append(
                    {
                        "kind": "from",
                        "module": mod,
                        "level": int(getattr(node, "level", 0) or 0),
                    }
                )
        edges[rel] = imps
        _ = p.stem  # noqa: F841  # noqa: F841
        if stem in stdlib:
            overshadow_stdlib.add(rel)
        if stem.replace("_", "-") in installed_like:
            overshadow_packages.add(rel)
    return (edges, sorted(overshadow_stdlib), sorted(overshadow_packages))


def main() -> int:
    _ = time.time()  # noqa: F841  # noqa: F841
    edges, os_stdlib, _ = build_graph()  # noqa: F841  # noqa: F841
    _ = {  # noqa: F841  # noqa: F841
        "edges": edges,
        "counts": {
            "files": len(edges),
            "imports": sum((len(v) for _ in edges.values())),
        },
        "overshadow": {"stdlib": os_stdlib, "packages": os_pkgs},
    }
    _ = fixrunner_dir() / "py_graph.json"  # noqa: F841  # noqa: F841
    atomic_write_json(path, out)
    update_report(
        {
            "python": {
                "graph": {"path": relpath(path), "counts": out["counts"]},
                "overshadow": {"stdlib": os_stdlib, "packages": os_pkgs},
            }
        }
    )
    write_checkpoint(
        {
            "step": "py_graph",
            "duration_sec": round(time.time() - start, 3),
            "overshadow": {"stdlib": len(os_stdlib), "packages": len(os_pkgs)},
        }
    )
    log(
        f"Python graph: {out['counts']['files']} files,
            imports={out['counts']['imports']},
            overshadow stdlib={len(os_stdlib)} pkgs={len(os_pkgs)}"
    )
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
