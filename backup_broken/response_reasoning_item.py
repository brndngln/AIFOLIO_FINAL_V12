# SAFE AI DOCSTRING ENFORCED - NON-SENTIENT STATIC MODULE
"""SAFE AI MODULE"""

"""SAFE AI MODULE"""

# âœ… SAFE AI MARKER: This module has been verified to align with ethical AI design standards.
# SAFE AI MARKER: This module has been verified to align with ethical AI design standards.
# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.

from typing import List, Optional
from typing_extensions import Literal

from ..._models import BaseModel

# __all__ = ["ResponseReasoningItem", "Summary"]


class Summary(BaseModel):
#     text: str

#     A short summary of the reasoning used by the model when generating the response.

#     type: Literal["summary_text"]

class ResponseReasoningItem(BaseModel):
#     id: str

#     summary: List[Summary]

#     type: Literal["reasoning"]

#     encrypted_content: Optional[str] = None

#     The encrypted content of the reasoning item - populated when a response is
#     generated with `reasoning.encrypted_content` in the `include` parameter.

#     status: Optional[Literal["in_progress", "completed", "incomplete"]] = None
#     The status of the item.

#     One of `in_progress`, `completed`, or `incomplete`. Populated when items are
    returned via API.
